% 
\RequirePackage{amsmath}
\documentclass[a4paper]{article}
\usepackage{Sweave}
\usepackage[margin=0.3in]{geometry}
\usepackage{enumitem}
\usepackage{float}
\usepackage[usenames,dvipsnames]{color}

\usepackage{titlesec}% http://ctan.org/pkg/titlesec
\titleformat{\section}%
  [hang]% <shape>
  {\normalfont\bfseries\Large}% <format>
  {}% <label>
  {0pt}% <sep>
  {}% <before code>
\renewcommand{\thesection}{}% Remove section references...
\renewcommand{\thesubsection}{}%... from subsections

\title{Module 2 - Measuring Dependence}
\author{Pawel Chilinski}

\begin{document}
\SweaveOpts{concordance=TRUE}
\maketitle
\subsection{Exercise 2.}
In the base library (loaded by default) of package R there is a data set trees available.
\begin{itemize}
\item Using function plot() obtain scatterplots of two pairs of variables:
Volume and Girth, Volume and Height.
<<fig=TRUE,height=10, width=20>>=
par(mfrow=c(1,2),mar=c(5,5,5,5))
plot(trees$Volume,trees$Girth, xlab="Volume",ylab="Girth",col="blue",cex.lab=2, cex=2)
plot(trees$Volume,trees$Height, xlab="Volume",ylab="Height",col="blue",cex.lab=2, cex=2)
@
\item Using function cor(), calculate an empirical correlation coefficient and
an empirical Spearman rank correlation coefficient for the two pairs of variables.
<<>>=
cor(trees$Volume,trees$Girth,method="pearson")
cor(trees$Volume,trees$Height,method="pearson")	
cor(trees$Volume,trees$Girth,method="spearman")
cor(trees$Volume,trees$Height,method="spearman")
@
\item Using function cor.test(), perform correlation tests of independency based
on Pearson's r coefficient and Spearman's $\rho$ coefficient for two pairs of
variables: Volume and Girth, Volume and Height, at a significance level 0.05
<<>>=
cor.test(trees$Volume,trees$Girth,method = "pearson",conf.level = 0.95)
cor.test(trees$Volume,trees$Height,method = "pearson",conf.level = 0.95)
cor.test(trees$Volume,trees$Girth,method = "spearman",conf.level = 0.95)
cor.test(trees$Volume,trees$Height,method = "spearman",conf.level = 0.95)
@
So all the tests allow us to reject the null hypothesis that correlation is 0 (using p cutoff value of 0.05).

\end{itemize}

\subsection{Exercise 3.}
File patients.txt contains 5 variables measured on 204 patients of Wroclaw outclinics. We are interested in examining dependence between education of patients and their marital status.
\begin{itemize}
\item Represent the data as a contingency table (use function table()).
<<>>=
patients <- read.table(file="patients.txt",header=T)
ed_mar_table <- table(patients[,c("education","marital")])
ed_mar_table
@
\item Using function summary() or chisq.test(), perform chi-square independence test.
<<>>=
summary(ed_mar_table)
test <- chisq.test(ed_mar_table)
test
#Should we reject H0?
test$p.value<0.05
@
We cannot reject $H_0$ that education and marital variables are independent using 0.05 significance level. 
\item Analyse Pearson residuals (chisq.test()\$residuals) and relate them with the test result.

If we compute standardized values of $n_{ij}$ under $H_0$ then we see that all the values are not much bigger than values expected only by chance (sampling error): 
<<>>=
test$residuals/sqrt(1-test$expected/sum(ed_mar_table))
@
so we shouldn't commit to reject $H_0$ which agrees with the test.
\item Perform chi-square independence tests for subgroups of men and women seperately (whenever number of observations is satisfactory).

We can only perform the test for the men data because it fulfils the rule of thumb that no cell of the expected table (under null hypothesis) should have values smaller than 5. We cannot reject
the $H_0$ in this case either.
<<>>=
patients_men <- patients[patients$gender=="male",]
ed_mar_men_table <- table(patients_men[,c("education","marital")])
ed_mar_men_table
ed_mar_men_table_expected <- outer(apply(ed_mar_men_table,1,sum)/sum(ed_mar_men_table),
                                   apply(ed_mar_men_table,2,sum)/sum(ed_mar_men_table))*
  sum(ed_mar_men_table)
ed_mar_men_table_expected
#Rule violated?
any(ed_mar_men_table_expected<5)
chisq.test(ed_mar_men_table)
patients_women <- patients[patients$gender=="female",]
ed_mar_women_table <- table(patients_women[,c("education","marital")])
ed_mar_women_table
ed_mar_wommen_table_expected <- outer(apply(ed_mar_women_table,1,sum)/sum(ed_mar_women_table),
                                      apply(ed_mar_women_table,2,sum)/sum(ed_mar_women_table))*
  sum(ed_mar_women_table)
ed_mar_wommen_table_expected
#Rule violated?
any(ed_mar_wommen_table_expected<5)
@
\item Using function fisher.test(), perform Fisher independence test.
<<>>=
f_test <- fisher.test(ed_mar_table)
f_test
#Should we reject H0 that variables are independent at 5% significance level?
f_test$p.value < 0.05
@
Result from the Fisher test doesn't allow us to reject $H_0$ either.

Using Fisher test we can test data from women:
<<>>=
f_test_women <- fisher.test(ed_mar_women_table)
f_test_women
f_test_women$p.value < 0.05
@
So wo cannot reject $H_0$ at 0.05 significance level.
\end{itemize}

\subsection{Exercise 4.}
File kids.txt contains pupils' answers in a questionaire about the most important quantities for them.
<<>>=
#load the data
kids <- read.table(file="kids.txt",header=T)
@
\begin{itemize}
\item Do answers concerning importance of looks depend on the gender of the questioned? Perform an appropriate test and interpret its result.
<<>>=
kids_table_gender_looks <- table(kids[,c("Gender","Looks")])
kids_table_gender_looks
kids_table_gender_looks_expected <- outer(apply(kids_table_gender_looks,1,sum)/
                                            sum(kids_table_gender_looks),
                                      apply(kids_table_gender_looks,2,sum)/
                                            sum(kids_table_gender_looks))*
  sum(kids_table_gender_looks)
kids_table_gender_looks_expected
#Can we perform Chi-square tests?
all(kids_table_gender_looks_expected>=5)
chisq_test_kids_gender_looks <- chisq.test(kids_table_gender_looks)
chisq_test_kids_gender_looks
#Can we reject H0?
chisq_test_kids_gender_looks$p.value < 0.05
@
The $H_0$ can be rejected because Chi-square tests gives p-value much smaller than 0.05.
\item What measures of dependence may be used in this situation?

We can use dependence measures suitable for nominal data only because gender is nominal and Looks is ordinal: Goodman-Kruskal dependence index (the average decrease of uncertainty about Looks if we know gender) , Conditional Gini index(where V(Looks|gender=female)=0 means that Looks is completely determined when gender is female), average value of conditional Gini index(average uncertainty about Looks when we know gender).
\item Calculate Gini index for variable Looks.
<<>>=
options(width=60)
#computes gini index for variable with name y
gini <- function(y){
  #compute gini index by summing up the products of estimates of the probabilty of giving given 
  #category and its complementary probabilty estimate.
  sum(table(kids[[y]])/nrow(kids)*(1-table(kids[[y]])/nrow(kids)))
}
gini("Looks")
@
\item Calculate Goodman-Kruskal dependence index for Gender and Looks.
<<>>=
#computes V(Y|x), where y,x are names of variables and x_val is specific value for x
gini_conditional <- function(y,x,x_val){
  cont_table <- table(kids[,c(x,y)])
  1-sum(sapply(unique(kids[[y]]),function(y_val){
    cont_table[x_val,y_val]/sum(cont_table[x_val,]) 
  })^2)
}

#computes E(V(Y|X)), where y,x are names of variables
expected_gini_conditional <- function(y,x){
  cont_table <- table(kids[,c(x,y)])
  sum(sapply(unique(kids[[x]]),function(x_val){
     sum(cont_table[x_val,])/sum(sum(cont_table)) * gini_conditional(y,x,x_val)  
  }))
}

#computes Goodman-Kruskal tau index, where y,x are names of variables
goodman_kruskal_tau <- function(y,x){
  (gini(y)- expected_gini_conditional(y,x))/gini(y)
}

#relative decrease of variability of Looks when we know Gender
goodman_kruskal_tau("Looks","Gender")
#relative decrease of variability of Gender when we know Looks
goodman_kruskal_tau("Gender","Looks")
@
\item Calculate Kendall's $\tau$ coefficient (function cor() or function Kendall() in package Kendall) for all pairs of ordered variables which are present in the data set.
<<>>=
options(width=60)
ordered_variables <- c("Grade","Age","Grades","Looks","Sports","Money")
variable_combinations <- combn(ordered_variables,2)
variable_combinations
for(col in 1:ncol(variable_combinations)){
  cat("variables: ",variable_combinations[1,col]," and ",variable_combinations[2,col],
      ", Kendall's tau = ",
      cor(kids[[variable_combinations[1,col]]],kids[[variable_combinations[2,col]]], 
          method="kendall"),"\n")
}
@
\end{itemize}
\end{document}
